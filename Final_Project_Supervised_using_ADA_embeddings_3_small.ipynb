{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30319f6e-5968-4694-8a88-73d86c5bc6a0",
   "metadata": {
    "id": "30319f6e-5968-4694-8a88-73d86c5bc6a0"
   },
   "source": [
    "# ADA word embeddings here..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "BK64pfpWd6zT",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BK64pfpWd6zT",
    "outputId": "2fd504d3-6d89-40df-dc38-9218fdff69a5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai\n",
      "  Downloading openai-1.30.3-py3-none-any.whl (320 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m320.6/320.6 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
      "Collecting httpx<1,>=0.23.0 (from openai)\n",
      "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.7.1)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.11.0)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
      "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.1)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
      "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
      "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.18.2)\n",
      "Installing collected packages: h11, httpcore, httpx, openai\n",
      "Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 openai-1.30.3\n"
     ]
    }
   ],
   "source": [
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "sWLNlZC4d6qW",
   "metadata": {
    "id": "sWLNlZC4d6qW"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ITHy1GXePSd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9ITHy1GXePSd",
    "outputId": "bc53b002-66bf-431c-b342-0eee8b10e3a2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "# Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "_DtmL_1xePLG",
   "metadata": {
    "id": "_DtmL_1xePLG"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3e62668",
   "metadata": {
    "id": "d3e62668"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12b6b88f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "12b6b88f",
    "outputId": "120a1d02-3f10-464c-a9c2-a863fcbb98a4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of 'wellness' rows: 24521\n",
      "Total number of 'not_wellness' rows: 176332\n",
      "RandomForestClassifier(random_state=42)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "NOT WELLNESS       0.88      0.92      0.90       100\n",
      "    WELLNESS       0.92      0.88      0.90       100\n",
      "\n",
      "    accuracy                           0.90       200\n",
      "   macro avg       0.90      0.90      0.90       200\n",
      "weighted avg       0.90      0.90      0.90       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import openai\n",
    "import os\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = 'your key here'\n",
    "\n",
    "# Load the data\n",
    "reviews = pd.read_json(\"/content/drive/MyDrive/Supervised_Final_Project/news_category_trainingdata.json\")\n",
    "\n",
    "# Prepare the data\n",
    "reviews['combined_text'] = reviews['headline'] + ' ' + reviews['short_description']\n",
    "reviews['wellness'] = np.where((reviews['category'].isin(['HEALTHY LIVING', 'WELLNESS'])), 1, 0)\n",
    "\n",
    "total_wellness = reviews[reviews['wellness'] == 1].shape[0]\n",
    "total_not_wellness = reviews[reviews['wellness'] == 0].shape[0]\n",
    "\n",
    "print(f\"Total number of 'wellness' rows: {total_wellness}\")\n",
    "print(f\"Total number of 'not_wellness' rows: {total_not_wellness}\")\n",
    "\n",
    "# Balance the data\n",
    "#sample_amount = 20000\n",
    "sample_amount = 1000\n",
    "wellness = reviews[reviews['wellness'] == 1].sample(n=sample_amount)\n",
    "not_wellness = reviews[reviews['wellness'] == 0].sample(n=sample_amount)\n",
    "review_sample = pd.concat([wellness, not_wellness])\n",
    "\n",
    "# Train-test split\n",
    "train_df, test_df = train_test_split(review_sample, test_size=0.1, stratify=review_sample['wellness'])\n",
    "\n",
    "# Set your OpenAI API key\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "# Function to get embeddings from OpenAI\n",
    "def get_embedding(client, text):\n",
    "\n",
    "    response = client.embeddings.create(\n",
    "        input=text,\n",
    "        model=\"text-embedding-3-small\"\n",
    "        #model=\"text-embedding-3-large\"\n",
    "        #model=\"text-embedding-ada-002\"\n",
    "    )\n",
    "\n",
    "    #print(response)\n",
    "    var_return = response.data[0].embedding\n",
    "    return var_return\n",
    "\n",
    "# Get embeddings for the train and test data\n",
    "train_embeddings = np.array([get_embedding(client, text) for text in train_df['combined_text']])\n",
    "test_embeddings = np.array([get_embedding(client, text) for text in test_df['combined_text']])\n",
    "\n",
    "# Train a classifier\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "print(clf)\n",
    "clf.fit(train_embeddings, train_df['wellness'])\n",
    "\n",
    "# Predict and evaluate\n",
    "test_preds = clf.predict(test_embeddings)\n",
    "report = classification_report(test_df['wellness'], test_preds, target_names=['NOT WELLNESS', 'WELLNESS'])\n",
    "print(report)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2e606c0",
   "metadata": {
    "id": "a2e606c0"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
